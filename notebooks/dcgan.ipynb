{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random_seed = 9292\n",
    "torch.manual_seed(random_seed)\n",
    "LATENT_DIM = 100\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 500\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)\n",
    "lr = 3e-4\n",
    "latent_dims = 100\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "training = CIFAR10(data_dir, train=True, transform=transform, download=True)\n",
    "testing = CIFAR10(data_dir, train=False, transform=transform, download=True)\n",
    "\n",
    "train_dataloader = DataLoader(training, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "test_dataloader = DataLoader(testing, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid = FrechetInceptionDistance(features=2048, normalize=True, reset_real_features=False).to(device)\n",
    "\n",
    "for i, (real_imgs, _) in enumerate(test_dataloader):\n",
    "    real_imgs = real_imgs.float().cuda()\n",
    "    fid.update(real_imgs, real=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from models.DCGAN import DCGANDiscriminator, DCGANGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = DCGANDiscriminator().to(device)\n",
    "gen = DCGANGenerator(LATENT_DIM).to(device)\n",
    "\n",
    "disc_optim = optim.Adam(disc.parameters(), lr=lr)\n",
    "gen_optim = optim.Adam(gen.parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "DCGAN_results = train_gan(disc, gen, disc_optim, gen_optim, criterion, 'models/DCGAN3', train_dataloader, test_dataloader, fid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f07cde9dbb177b152a57688f67b18487bd7574344579868b86e37fc91c0932c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
