{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random_seed = 9292\n",
    "torch.manual_seed(random_seed)\n",
    "LATENT_DIM = 100\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 500\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)\n",
    "lr = 3e-4\n",
    "latent_dims = 100\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "training = CIFAR10(data_dir, train=True, transform=transform, download=True)\n",
    "testing = CIFAR10(data_dir, train=False, transform=transform, download=True)\n",
    "\n",
    "train_dataloader = DataLoader(training, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "test_dataloader = DataLoader(testing, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid = FrechetInceptionDistance(features=2048, normalize=True, reset_real_features=False).to(device)\n",
    "\n",
    "for i, (real_imgs, _) in enumerate(test_dataloader):\n",
    "    real_imgs = real_imgs.float().cuda()\n",
    "    fid.update(real_imgs, real=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from models.cdcgan import ConditionalDCGANDiscriminator, ConditionalDCGANGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_conditional_gan(disc, gen, disc_optim, gen_optim, criterion, basedir, train_dataloader, test_dataloader, fid):\n",
    "    disc.train()\n",
    "    gen.train()\n",
    "    train_num_batches = len(train_dataloader)\n",
    "    dict_result = {}\n",
    "    dict_result['avg_disc_loss'], dict_result['avg_gen_loss'], dict_result['avg_real_acc'], dict_result['avg_fake_acc'] = [], [], [], []\n",
    "    dict_result['test_disc_loss'], dict_result['test_gen_loss'], dict_result['test_real_acc'], dict_result['test_fake_acc'], dict_result['fid_score'] = [], [], [], [], []\n",
    "\n",
    "    test_conditional_gan(gen, disc, criterion, dict_result, 0, basedir, test_dataloader, fid)\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_disc_loss, epoch_gen_loss, epoch_real_acc, epoch_fake_acc = [], [], [], []\n",
    "        for i, (real_imgs, labels) in enumerate(train_dataloader):\n",
    "            random_labels = torch.randint(0, 10, (real_imgs.shape[0], )).to(device)\n",
    "\n",
    "            real_imgs = real_imgs.float().cuda()\n",
    "            noise = torch.randn(LATENT_DIM*real_imgs.shape[0]).to(device)\n",
    "            fake_imgs = gen(noise.reshape(real_imgs.shape[0], LATENT_DIM), random_labels)\n",
    "\n",
    "            disc_real = disc(real_imgs, labels.to(device))\n",
    "            disc_fake = disc(fake_imgs, random_labels)\n",
    "\n",
    "            real_acc = torch.sum(torch.round(disc_real) == torch.ones_like(disc_real)) / len(disc_real)\n",
    "            fake_acc = torch.sum(torch.round(disc_fake) == torch.zeros_like(disc_fake)) / len(disc_fake)\n",
    "        \n",
    "            real_loss = criterion(disc_real, torch.ones_like(disc_real))\n",
    "            fake_loss = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "            disc_loss = (real_loss + fake_loss) / 2\n",
    "            disc.zero_grad()\n",
    "            disc_loss.backward(retain_graph=True)\n",
    "            disc_optim.step()\n",
    "\n",
    "            epoch_disc_loss.append(disc_loss.item()) \n",
    "            epoch_real_acc.append(real_acc.item()) \n",
    "            epoch_fake_acc.append(fake_acc.item()) \n",
    "\n",
    "            disc_fake = disc(fake_imgs, random_labels)\n",
    "            gen_loss = criterion(disc_fake, torch.ones_like(disc_fake))\n",
    "            gen.zero_grad()\n",
    "            gen_loss.backward()\n",
    "            gen_optim.step()\n",
    "\n",
    "            epoch_gen_loss.append(gen_loss.item())\n",
    "\n",
    "            progress = int(((i+1)/train_num_batches)*20)\n",
    "            print(f\"{epoch+1}/{NUM_EPOCHS} [{'='*progress}{' '*(20-progress)}] {i+1}/{train_num_batches}\", end='\\r', flush=True)\n",
    "\n",
    "            del disc_loss, gen_loss, real_acc, fake_acc, noise, fake_imgs, disc_real, disc_fake, real_loss, fake_loss, random_labels\n",
    "\n",
    "        # dcgan_agent.output_train_graphs('.')\n",
    "        \n",
    "        avg_disc_loss = sum(epoch_disc_loss) / len(epoch_disc_loss)\n",
    "        avg_gen_loss = sum(epoch_gen_loss) / len(epoch_gen_loss)\n",
    "        avg_real_acc = sum(epoch_real_acc) / len(epoch_real_acc)\n",
    "        avg_fake_acc = sum(epoch_fake_acc) / len(epoch_fake_acc)\n",
    "\n",
    "        dict_result['avg_disc_loss'].append(avg_disc_loss)\n",
    "        dict_result['avg_gen_loss'].append(avg_gen_loss)\n",
    "        dict_result['avg_real_acc'].append(avg_real_acc)\n",
    "        dict_result['avg_fake_acc'].append(avg_fake_acc)\n",
    "\n",
    "        del epoch_disc_loss, epoch_gen_loss, epoch_real_acc, epoch_fake_acc\n",
    "\n",
    "        plot_training_graphs(basedir, dict_result['avg_disc_loss'], dict_result['avg_gen_loss'], dict_result['avg_real_acc'], dict_result['avg_fake_acc'])\n",
    "\n",
    "        print(f'disc loss: {avg_disc_loss:5.2f}  gen loss: {avg_gen_loss:5.2f}  real acc: {avg_real_acc:5.2f}  fake_acc: {avg_fake_acc:5.2f}')\n",
    "        del avg_disc_loss, avg_gen_loss, avg_real_acc, avg_fake_acc\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            test_conditional_gan(gen, disc, criterion, dict_result, epoch, basedir, test_dataloader, fid)\n",
    "            torch.save(gen.state_dict(), basedir+f'/saves/model{str(epoch+1)}.pt')\n",
    "\n",
    "    return dict_result\n",
    "\n",
    "\n",
    "def test_conditional_gan(gen, disc, criterion, dict_result, epoch, basedir, test_dataloader, fid):\n",
    "    gen.eval()\n",
    "    disc.eval()\n",
    "    with torch.no_grad():\n",
    "        epoch_disc_loss, epoch_gen_loss, epoch_real_acc, epoch_fake_acc = [], [], [], []\n",
    "\n",
    "        for i, (real_imgs, labels) in enumerate(test_dataloader):\n",
    "            random_labels = torch.randint(0, 10, (real_imgs.shape[0], )).to(device)\n",
    "\n",
    "            real_imgs = real_imgs.float().cuda()\n",
    "            noise = torch.randn(LATENT_DIM*real_imgs.shape[0]).to(device)\n",
    "            fake_imgs = gen(noise.reshape(real_imgs.shape[0], LATENT_DIM), random_labels)\n",
    "\n",
    "            disc_real = disc(real_imgs, labels.to(device))\n",
    "            disc_fake = disc(fake_imgs, random_labels)\n",
    "\n",
    "            real_acc = torch.sum(torch.round(disc_real) == torch.ones_like(disc_real)) / len(disc_real)\n",
    "            fake_acc = torch.sum(torch.round(disc_fake) == torch.zeros_like(disc_fake)) / len(disc_fake)\n",
    "            \n",
    "            real_loss = criterion(disc_real, torch.ones_like(disc_real))\n",
    "            fake_loss = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "            disc_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "            disc_fake = disc(fake_imgs, random_labels)\n",
    "            gen_loss = criterion(disc_fake, torch.ones_like(disc_fake))\n",
    "\n",
    "            fid.update(fake_imgs, real=False)\n",
    "\n",
    "            epoch_disc_loss.append(disc_loss.item())\n",
    "            epoch_gen_loss.append(gen_loss.item())\n",
    "            epoch_real_acc.append(real_acc.item())\n",
    "            epoch_fake_acc.append(fake_acc.item())\n",
    "\n",
    "            progress = int(((i+1)/len(test_dataloader))*20)\n",
    "            print(f\"test [{'='*progress}{' '*(20-progress)}] {i+1}/{len(test_dataloader)}\", end='\\r', flush=True)\n",
    "\n",
    "            del disc_loss, gen_loss, real_acc, fake_acc, noise, fake_imgs, disc_real, disc_fake, random_labels\n",
    "\n",
    "        test_disc_loss = sum(epoch_disc_loss) / len(epoch_disc_loss)\n",
    "        test_gen_loss = sum(epoch_gen_loss) / len(epoch_gen_loss)\n",
    "        test_real_acc = sum(epoch_real_acc) / len(epoch_real_acc)\n",
    "        test_fake_acc = sum(epoch_fake_acc) / len(epoch_fake_acc)\n",
    "        dict_result['test_disc_loss'].append(test_disc_loss)\n",
    "        dict_result['test_gen_loss'].append(test_gen_loss)\n",
    "        dict_result['test_real_acc'].append(test_real_acc)\n",
    "        dict_result['test_fake_acc'].append(test_fake_acc)\n",
    "        del epoch_gen_loss, epoch_disc_loss, epoch_real_acc, epoch_fake_acc\n",
    "\n",
    "        test_graphs(basedir, dict_result)\n",
    "\n",
    "        fid_score = fid.compute().item()\n",
    "        fid.reset()\n",
    "        dict_result['fid_score'].append(fid_score)\n",
    "\n",
    "        output_imgs(basedir, gen, epoch, test_disc_loss, test_gen_loss, fid_score, labels=True)\n",
    "        \n",
    "        gen.train()\n",
    "        disc.train()\n",
    "        del fid_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disc loss:  0.34  gen loss:  4.30  real acc:  0.82  fake_acc:  0.82\n",
      "disc loss:  0.63  gen loss:  1.34  real acc:  0.68  fake_acc:  0.57\n",
      "disc loss:  0.62  gen loss:  1.76  real acc:  0.69  fake_acc:  0.70\n",
      "disc loss:  0.62  gen loss:  1.19  real acc:  0.64  fake_acc:  0.69\n",
      "disc loss:  0.62  gen loss:  1.39  real acc:  0.67  fake_acc:  0.70\n",
      "disc loss:  0.61  gen loss:  1.30  real acc:  0.65  fake_acc:  0.69\n",
      "disc loss:  0.62  gen loss:  1.43  real acc:  0.66  fake_acc:  0.69\n",
      "disc loss:  0.61  gen loss:  2.02  real acc:  0.71  fake_acc:  0.75\n",
      "disc loss:  0.56  gen loss:  1.65  real acc:  0.69  fake_acc:  0.79\n",
      "disc loss:  0.54  gen loss:  1.64  real acc:  0.69  fake_acc:  0.77\n",
      "disc loss:  0.52  gen loss:  1.72  real acc:  0.72  fake_acc:  0.81\n",
      "disc loss:  0.50  gen loss:  1.82  real acc:  0.72  fake_acc:  0.84\n",
      "disc loss:  0.45  gen loss:  2.34  real acc:  0.77  fake_acc:  0.88\n",
      "disc loss:  0.44  gen loss:  2.30  real acc:  0.78  fake_acc:  0.88\n",
      "disc loss:  0.40  gen loss:  2.31  real acc:  0.79  fake_acc:  0.89\n",
      "disc loss:  0.41  gen loss:  2.51  real acc:  0.79  fake_acc:  0.89\n",
      "disc loss:  0.36  gen loss:  2.45  real acc:  0.81  fake_acc:  0.92\n",
      "disc loss:  0.34  gen loss:  2.69  real acc:  0.83  fake_acc:  0.93\n",
      "disc loss:  0.33  gen loss:  2.79  real acc:  0.83  fake_acc:  0.92\n",
      "disc loss:  0.35  gen loss:  2.58  real acc:  0.82  fake_acc:  0.91\n",
      "disc loss:  0.39  gen loss:  2.49  real acc:  0.79  fake_acc:  0.89\n",
      "disc loss:  0.33  gen loss:  2.81  real acc:  0.83  fake_acc:  0.90\n",
      "disc loss:  0.33  gen loss:  2.93  real acc:  0.84  fake_acc:  0.91\n",
      "disc loss:  0.31  gen loss:  3.03  real acc:  0.85  fake_acc:  0.91\n",
      "disc loss:  0.32  gen loss:  3.15  real acc:  0.84  fake_acc:  0.90\n",
      "disc loss:  0.33  gen loss:  3.07  real acc:  0.84  fake_acc:  0.89\n",
      "disc loss:  0.34  gen loss:  2.87  real acc:  0.83  fake_acc:  0.89\n",
      "disc loss:  0.32  gen loss:  3.01  real acc:  0.85  fake_acc:  0.90\n",
      "disc loss:  0.35  gen loss:  2.73  real acc:  0.82  fake_acc:  0.89\n",
      "disc loss:  0.33  gen loss:  3.17  real acc:  0.84  fake_acc:  0.90\n",
      "disc loss:  0.36  gen loss:  3.25  real acc:  0.82  fake_acc:  0.88\n",
      "disc loss:  0.31  gen loss:  2.72  real acc:  0.84  fake_acc:  0.91\n",
      "disc loss:  0.32  gen loss:  3.12  real acc:  0.84  fake_acc:  0.90\n",
      "disc loss:  0.28  gen loss:  3.18  real acc:  0.86  fake_acc:  0.92\n",
      "disc loss:  0.29  gen loss:  3.41  real acc:  0.86  fake_acc:  0.92\n",
      "disc loss:  0.29  gen loss:  3.45  real acc:  0.86  fake_acc:  0.92\n",
      "disc loss:  0.32  gen loss:  2.97  real acc:  0.84  fake_acc:  0.91\n",
      "disc loss:  0.31  gen loss:  3.06  real acc:  0.84  fake_acc:  0.91\n",
      "disc loss:  0.28  gen loss:  3.26  real acc:  0.86  fake_acc:  0.92\n",
      "disc loss:  0.30  gen loss:  3.14  real acc:  0.85  fake_acc:  0.92\n",
      "disc loss:  0.31  gen loss:  3.17  real acc:  0.85  fake_acc:  0.91\n",
      "disc loss:  0.28  gen loss:  3.32  real acc:  0.86  fake_acc:  0.92\n",
      "disc loss:  0.33  gen loss:  3.34  real acc:  0.85  fake_acc:  0.91\n",
      "disc loss:  0.32  gen loss:  3.30  real acc:  0.85  fake_acc:  0.91\n",
      "disc loss:  0.33  gen loss:  3.27  real acc:  0.84  fake_acc:  0.90\n",
      "disc loss:  0.32  gen loss:  2.98  real acc:  0.84  fake_acc:  0.91\n",
      "disc loss:  0.28  gen loss:  3.26  real acc:  0.86  fake_acc:  0.92\n",
      "disc loss:  0.30  gen loss:  3.41  real acc:  0.86  fake_acc:  0.92\n",
      "disc loss:  0.33  gen loss:  3.56  real acc:  0.85  fake_acc:  0.90\n",
      "disc loss:  0.27  gen loss:  3.50  real acc:  0.86  fake_acc:  0.93\n",
      "disc loss:  0.29  gen loss:  3.30  real acc:  0.86  fake_acc:  0.92\n",
      "disc loss:  0.30  gen loss:  3.24  real acc:  0.85  fake_acc:  0.92\n",
      "disc loss:  0.30  gen loss:  4.31  real acc:  0.87  fake_acc:  0.92\n",
      "disc loss:  0.26  gen loss:  3.19  real acc:  0.87  fake_acc:  0.94\n",
      "disc loss:  0.26  gen loss:  3.76  real acc:  0.87  fake_acc:  0.93\n",
      "disc loss:  0.28  gen loss:  3.71  real acc:  0.87  fake_acc:  0.93\n",
      "disc loss:  0.27  gen loss:  3.40  real acc:  0.86  fake_acc:  0.93\n",
      "disc loss:  0.28  gen loss:  3.80  real acc:  0.87  fake_acc:  0.93\n",
      "disc loss:  0.27  gen loss:  3.66  real acc:  0.87  fake_acc:  0.93\n",
      "disc loss:  0.27  gen loss:  3.36  real acc:  0.87  fake_acc:  0.93\n",
      "disc loss:  0.26  gen loss:  4.49  real acc:  0.88  fake_acc:  0.93\n",
      "disc loss:  0.25  gen loss:  3.20  real acc:  0.88  fake_acc:  0.94\n",
      "disc loss:  0.26  gen loss:  3.89  real acc:  0.87  fake_acc:  0.94\n",
      "disc loss:  0.26  gen loss:  3.72  real acc:  0.88  fake_acc:  0.94\n",
      "disc loss:  0.27  gen loss:  3.71  real acc:  0.88  fake_acc:  0.93\n",
      "disc loss:  0.26  gen loss:  3.78  real acc:  0.87  fake_acc:  0.94\n",
      "disc loss:  0.27  gen loss:  3.96  real acc:  0.88  fake_acc:  0.94\n",
      "disc loss:  0.22  gen loss:  3.44  real acc:  0.89  fake_acc:  0.96\n",
      "disc loss:  0.26  gen loss:  3.44  real acc:  0.87  fake_acc:  0.94\n",
      "disc loss:  0.28  gen loss:  3.95  real acc:  0.87  fake_acc:  0.94\n",
      "disc loss:  0.27  gen loss:  4.16  real acc:  0.88  fake_acc:  0.94\n",
      "disc loss:  0.26  gen loss:  3.32  real acc:  0.87  fake_acc:  0.95\n",
      "disc loss:  0.26  gen loss:  5.46  real acc:  0.89  fake_acc:  0.94\n",
      "disc loss:  0.26  gen loss:  3.25  real acc:  0.87  fake_acc:  0.95\n",
      "disc loss:  0.28  gen loss:  4.27  real acc:  0.89  fake_acc:  0.94\n",
      "disc loss:  0.27  gen loss:  3.39  real acc:  0.87  fake_acc:  0.94\n",
      "disc loss:  0.25  gen loss:  4.69  real acc:  0.89  fake_acc:  0.94\n",
      "disc loss:  0.25  gen loss:  3.86  real acc:  0.88  fake_acc:  0.95\n",
      "disc loss:  0.25  gen loss:  3.50  real acc:  0.88  fake_acc:  0.95\n",
      "disc loss:  0.23  gen loss:  3.58  real acc:  0.88  fake_acc:  0.95\n",
      "disc loss:  0.31  gen loss:  5.84  real acc:  0.90  fake_acc:  0.94\n",
      "disc loss:  0.23  gen loss:  3.35  real acc:  0.89  fake_acc:  0.96\n",
      "disc loss:  0.22  gen loss:  3.72  real acc:  0.89  fake_acc:  0.96\n",
      "disc loss:  0.23  gen loss:  3.94  real acc:  0.89  fake_acc:  0.96\n",
      "disc loss:  0.22  gen loss:  5.01  real acc:  0.90  fake_acc:  0.95\n",
      "disc loss:  0.22  gen loss:  3.86  real acc:  0.89  fake_acc:  0.96\n",
      "disc loss:  0.20  gen loss:  3.66  real acc:  0.90  fake_acc:  0.97\n",
      "disc loss:  0.24  gen loss:  4.34  real acc:  0.89  fake_acc:  0.95\n",
      "disc loss:  0.23  gen loss:  4.19  real acc:  0.90  fake_acc:  0.96\n",
      "disc loss:  0.23  gen loss:  4.33  real acc:  0.90  fake_acc:  0.96\n",
      "disc loss:  0.23  gen loss:  3.61  real acc:  0.89  fake_acc:  0.97\n",
      "disc loss:  0.24  gen loss:  4.02  real acc:  0.89  fake_acc:  0.95\n",
      "disc loss:  0.25  gen loss:  4.70  real acc:  0.89  fake_acc:  0.95\n",
      "disc loss:  0.25  gen loss:  3.71  real acc:  0.89  fake_acc:  0.96\n",
      "disc loss:  0.22  gen loss:  3.96  real acc:  0.89  fake_acc:  0.97\n",
      "disc loss:  0.19  gen loss:  5.28  real acc:  0.92  fake_acc:  0.97\n",
      "disc loss:  0.22  gen loss:  4.55  real acc:  0.90  fake_acc:  0.97\n",
      "disc loss:  0.24  gen loss:  4.22  real acc:  0.89  fake_acc:  0.96\n",
      "disc loss:  0.21  gen loss:  4.78  real acc:  0.91  fake_acc:  0.96\n",
      "disc loss:  0.21  gen loss:  3.72  real acc:  0.90  fake_acc:  0.97\n",
      "test [====================] 157/157\r"
     ]
    }
   ],
   "source": [
    "disc = ConditionalDCGANDiscriminator().to(device)\n",
    "gen = ConditionalDCGANGenerator(LATENT_DIM).to(device)\n",
    "\n",
    "disc_optim = optim.Adam(disc.parameters(), lr=1e-4)\n",
    "gen_optim = optim.Adam(gen.parameters(), lr=4e-4)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "ConditionalDCGAN_results = train_conditional_gan(disc, gen, disc_optim, gen_optim, criterion, 'models/C-DCGAN_run_8', train_dataloader, test_dataloader, fid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f07cde9dbb177b152a57688f67b18487bd7574344579868b86e37fc91c0932c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
