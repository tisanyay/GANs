{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random_seed = 9292\n",
    "torch.manual_seed(random_seed)\n",
    "LATENT_DIM = 100\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 500\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)\n",
    "lr = 3e-4\n",
    "latent_dims = 100\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "training = CIFAR10(data_dir, train=True, transform=transform, download=True)\n",
    "testing = CIFAR10(data_dir, train=False, transform=transform, download=True)\n",
    "\n",
    "train_dataloader = DataLoader(training, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "test_dataloader = DataLoader(testing, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid = FrechetInceptionDistance(features=2048, normalize=True, reset_real_features=False).to(device)\n",
    "\n",
    "for i, (real_imgs, _) in enumerate(test_dataloader):\n",
    "    real_imgs = real_imgs.float().cuda()\n",
    "    fid.update(real_imgs, real=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import * \n",
    "from models.acgan import ACGANDiscriminator, ACGANGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "def train_acgan(disc, gen, disc_optim, gen_optim, disc_criterion, aux_criterion, basedir, train_dataloader, test_dataloader):\n",
    "    disc.train()\n",
    "    gen.train()\n",
    "    train_num_batches = len(train_dataloader)\n",
    "    dict_result = {}\n",
    "    dict_result['avg_errD_real'], dict_result['avg_gen_loss'], dict_result['avg_errD_fake'], dict_result['avg_accuracy'] = [], [], [], []\n",
    "    dict_result['test_errD_real'], dict_result['test_gen_loss'], dict_result['test_errD_fake'], dict_result['test_accuracy'], dict_result['fid_score'] = [], [], [], [], []\n",
    "    \n",
    "    test_acgan(gen, disc, disc_criterion, aux_criterion, dict_result, 0, basedir, test_dataloader, fid)\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_errD_real, epoch_errD_fake, epoch_gen_loss, epoch_accuracy = [], [], [], []\n",
    "        for i, (real_imgs, labels) in enumerate(train_dataloader):\n",
    "            disc.zero_grad()\n",
    "            random_labels = torch.randint(0, 10, (real_imgs.shape[0], )).to(device)\n",
    "            # real disc training\n",
    "            disc_real, classes_real = disc(real_imgs.to(device))\n",
    "\n",
    "            _batch_size = labels.shape[0]\n",
    "            \n",
    "            labels = labels.resize_(_batch_size).to(device)\n",
    "\n",
    "            disc_real = disc_criterion(disc_real, torch.ones_like(disc_real))\n",
    "            aux_real = aux_criterion(classes_real, labels)\n",
    "\n",
    "            errD_real = disc_real + aux_real \n",
    "            errD_real.backward()\n",
    "\n",
    "            accuracy = compute_acc(classes_real, labels)\n",
    "\n",
    "            # fake disc training\n",
    "            real_imgs = real_imgs.float().cuda()\n",
    "            noise = torch.randn(LATENT_DIM*real_imgs.shape[0]).to(device)\n",
    "            fake_labels = torch.randint(0, 10, (_batch_size, )).resize_(_batch_size).to(device)\n",
    "            fake_imgs = gen(noise.reshape(real_imgs.shape[0], LATENT_DIM))\n",
    "\n",
    "            disc_fake, classes_fake = disc(fake_imgs)\n",
    "\n",
    "            disc_fake = disc_criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "            aux_fake = aux_criterion(classes_fake, fake_labels)\n",
    "            errD_fake = disc_fake + aux_fake\n",
    "        \n",
    "            errD_fake.backward(retain_graph=True)\n",
    "            disc_optim.step()\n",
    "\n",
    "            epoch_errD_real.append(errD_real.item()) \n",
    "            epoch_errD_fake.append(errD_fake.item()) \n",
    "            epoch_accuracy.append(accuracy)\n",
    "\n",
    "            disc_fake, classes_fake = disc(fake_imgs)\n",
    "            gen_fake = disc_criterion(disc_fake, torch.ones_like(disc_fake))\n",
    "            gen_aux = aux_criterion(classes_fake, fake_labels)\n",
    "            gen_loss = gen_fake + gen_aux\n",
    "            gen.zero_grad()\n",
    "            gen_loss.backward()\n",
    "            gen_optim.step()\n",
    "\n",
    "            epoch_gen_loss.append(gen_loss.item())\n",
    "\n",
    "            progress = int(((i+1)/train_num_batches)*20)\n",
    "            print(f\"{epoch+1}/{NUM_EPOCHS} [{'='*progress}{' '*(20-progress)}] {i+1}/{train_num_batches}\", end='\\r', flush=True)\n",
    "\n",
    "            del gen_loss, noise, fake_imgs, disc_real, disc_fake, random_labels\n",
    "\n",
    "        # dcgan_agent.output_train_graphs('.')\n",
    "        \n",
    "        avg_errD_real = sum(epoch_errD_real) / len(epoch_errD_real)\n",
    "        avg_errD_fake = sum(epoch_errD_fake) / len(epoch_errD_fake)\n",
    "        avg_gen_loss = sum(epoch_gen_loss) / len(epoch_gen_loss)\n",
    "        avg_accuracy = sum(epoch_accuracy) / len(epoch_accuracy)\n",
    "\n",
    "        dict_result['avg_errD_real'].append(avg_errD_real)\n",
    "        dict_result['avg_errD_fake'].append(avg_errD_fake)\n",
    "        dict_result['avg_gen_loss'].append(avg_gen_loss)\n",
    "        dict_result['avg_accuracy'].append(avg_accuracy)\n",
    "\n",
    "        # plot_training_graphs(basedir, dict_result['avg_disc_loss'], dict_result['avg_gen_loss'], dict_result['avg_real_acc'], dict_result['avg_fake_acc'])\n",
    "\n",
    "        fig = plt.figure(figsize=(15,9))\n",
    "        plt.plot(dict_result['avg_errD_real'])\n",
    "        plt.plot(dict_result['avg_errD_fake'])\n",
    "        plt.plot(dict_result['avg_gen_loss'])\n",
    "        plt.legend(['discriminator loss real', 'discriminator loss fake', 'generator loss'])\n",
    "        plt.title('Discriminator loss vs Generator loss')\n",
    "        plt.savefig(basedir+'/graphs/train_loss_graph.jpg')\n",
    "        plt.close()\n",
    "\n",
    "        fig = plt.figure(figsize=(15,9))\n",
    "        plt.plot(dict_result['avg_accuracy'])\n",
    "        plt.title('Accuracy')\n",
    "        plt.savefig(basedir+'/graphs/train_acc_graph.jpg')\n",
    "        plt.close()\n",
    "\n",
    "        print(f'\\nerrD_real loss: {avg_errD_real:5.2f}  errD_fake loss: {avg_errD_fake:5.2f}  gen loss: {avg_gen_loss:5.2f}  acc: {avg_accuracy:5.2f}\\n')\n",
    "        del avg_errD_fake, avg_gen_loss, avg_errD_real, avg_accuracy\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            test_acgan(gen, disc, disc_criterion, aux_criterion, dict_result, epoch, basedir, test_dataloader, fid)\n",
    "            torch.save(gen.state_dict(), basedir+f'/saves/model{str(epoch+1)}.pt')\n",
    "\n",
    "    return dict_result\n",
    "\n",
    "def test_acgan(gen, disc, disc_criterion, aux_criterion, dict_result, epoch, basedir, test_dataloader, fid):\n",
    "    gen.eval()\n",
    "    disc.eval()\n",
    "    with torch.no_grad():\n",
    "        epoch_errD_real, epoch_errD_fake, epoch_gen_loss, epoch_accuracy = [], [], [], []\n",
    "        train_num_batches = len(test_dataloader)\n",
    "        for i, (real_imgs, labels) in enumerate(test_dataloader):\n",
    "            # disc_loss, gen_loss, real_acc, fake_acc = dcgan_agent.test_gan(real_imgs)\n",
    "            random_labels = torch.randint(0, 10, (real_imgs.shape[0], )).to(device)\n",
    "            # real disc training\n",
    "            disc_real, classes_real = disc(real_imgs.to(device))\n",
    "\n",
    "            _batch_size = labels.shape[0]\n",
    "            \n",
    "            labels = labels.resize_(_batch_size).to(device)\n",
    "\n",
    "            disc_real = disc_criterion(disc_real, torch.ones_like(disc_real))\n",
    "            aux_real = aux_criterion(classes_real, labels)\n",
    "\n",
    "            errD_real = disc_real + aux_real \n",
    "\n",
    "            accuracy = compute_acc(classes_real, labels)\n",
    "\n",
    "            # fake disc training\n",
    "            real_imgs = real_imgs.float().cuda()\n",
    "            noise = torch.randn(LATENT_DIM*real_imgs.shape[0]).to(device)\n",
    "            fake_labels = torch.randint(0, 10, (_batch_size, )).resize_(_batch_size).to(device)\n",
    "            fake_imgs = gen(noise.reshape(real_imgs.shape[0], LATENT_DIM))\n",
    "\n",
    "            disc_fake, classes_fake = disc(fake_imgs)\n",
    "\n",
    "            disc_fake = disc_criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "            aux_fake = aux_criterion(classes_fake, fake_labels)\n",
    "            errD_fake = disc_fake + aux_fake\n",
    "        \n",
    "            epoch_errD_real.append(errD_real.item()) \n",
    "            epoch_errD_fake.append(errD_fake.item()) \n",
    "            epoch_accuracy.append(accuracy)\n",
    "            \n",
    "            disc_fake, classes_fake = disc(fake_imgs)\n",
    "            # gen_loss = criterion(disc_fake, torch.ones_like(disc_fake))\n",
    "            gen_fake = disc_criterion(disc_fake, torch.ones_like(disc_fake))\n",
    "            gen_aux = aux_criterion(classes_fake, fake_labels)\n",
    "            gen_loss = gen_fake + gen_aux\n",
    "\n",
    "            epoch_gen_loss.append(gen_loss.item())\n",
    "\n",
    "            progress = int(((i+1)/train_num_batches)*20)\n",
    "            print(f\"{epoch+1}/{NUM_EPOCHS} [{'='*progress}{' '*(20-progress)}] {i+1}/{train_num_batches}\", end='\\r', flush=True)\n",
    "\n",
    "            fid.update(fake_imgs, real=False)\n",
    "\n",
    "            del gen_loss, noise, fake_imgs, disc_real, disc_fake, random_labels\n",
    "\n",
    "        test_errD_real = sum(epoch_errD_real) / len(epoch_errD_real)\n",
    "        test_errD_fake = sum(epoch_errD_fake) / len(epoch_errD_fake)\n",
    "        test_gen_loss =  sum(epoch_gen_loss) / len(epoch_gen_loss)\n",
    "        test_accuracy = sum(epoch_accuracy) / len(epoch_accuracy)\n",
    "        dict_result['test_errD_real'].append(test_errD_real)\n",
    "        dict_result['test_gen_loss'].append(test_gen_loss)\n",
    "        dict_result['test_errD_fake'].append(test_errD_fake)\n",
    "        dict_result['test_accuracy'].append(test_accuracy)\n",
    "        del epoch_gen_loss, epoch_errD_real, epoch_errD_fake, epoch_accuracy \n",
    "\n",
    "        # test_graphs(basedir, dict_result)\n",
    "        fig = plt.figure(figsize=(15,9))\n",
    "        plt.plot(dict_result['test_errD_real'])\n",
    "        plt.plot(dict_result['test_errD_fake'])\n",
    "        plt.plot(dict_result['test_gen_loss'])\n",
    "        plt.plot(dict_result['fid_score'])\n",
    "        plt.legend(['discriminator loss real', 'discriminator loss fake', 'generator loss', 'fid'])\n",
    "        plt.title('Discriminator loss vs Generator loss vs FID')\n",
    "        plt.savefig(basedir+'/graphs/test_loss_graph.jpg')\n",
    "        plt.close()\n",
    "\n",
    "        fig = plt.figure(figsize=(15,9))\n",
    "        plt.plot(dict_result['test_accuracy'])\n",
    "        plt.title('Accuracy')\n",
    "        plt.savefig(basedir+'/graphs/test_acc_graph.jpg')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        fid_score = fid.compute().item()\n",
    "        fid.reset()\n",
    "        dict_result['fid_score'].append(fid_score)\n",
    "\n",
    "        # output_imgs(basedir, gen, epoch, test_disc_loss, test_gen_loss, fid_score)\n",
    "        rows, columns = 8, 6\n",
    "\n",
    "        noise = torch.randn(LATENT_DIM*rows*columns).to(device)\n",
    "        fake_imgs = gen(noise.reshape(rows*columns, LATENT_DIM))\n",
    "        _, classes_predict = disc(fake_imgs)\n",
    "        classes_predict = classes_predict.data.max(1)[1]\n",
    "        fig, axs = plt.subplots(rows, columns, figsize=(20, 30))\n",
    "        for i in range(rows*columns):\n",
    "            ax = axs[i//columns, i%columns]\n",
    "            img = (fake_imgs[i].cpu().permute(1,2,0).detach().numpy() + 1) / 2\n",
    "            ax.imshow(img, cmap='Greys')\n",
    "            ax.set_title(classes[classes_predict[i]])\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.text(-192, -310, f'epoch: {str(epoch+1)}   discriminator loss real: {test_errD_real:5.2f}\\n   discriminator loss fake: {test_errD_fake:5.2f}   generator loss: {test_gen_loss:5.2f}   fid: {fid_score:5.2f}', fontsize=30, ha='left', va='top')\n",
    "        plt.savefig(basedir+f'/imgs/img{epoch+1}.jpg')\n",
    "        plt.close()\n",
    "\n",
    "        del rows, columns, noise, fake_imgs\n",
    "\n",
    "        gen.train()\n",
    "        disc.train()\n",
    "        del fid_score\n",
    "\n",
    "# compute the current classification accuracy\n",
    "def compute_acc(preds, labels):\n",
    "    correct = 0\n",
    "    preds_ = preds.data.max(1)[1]\n",
    "    correct = preds_.eq(labels.data).cpu().sum()\n",
    "    acc = float(correct) / float(len(labels.data)) * 100.0\n",
    "    return acc\n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/500 [====================] 782/782\n",
      "errD_real loss:  0.48  errD_fake loss:  0.56  gen loss:  0.93  acc: 18.40\n",
      "\n",
      "2/500 [====================] 782/782\n",
      "errD_real loss:  0.41  errD_fake loss:  0.53  gen loss:  1.04  acc: 23.19\n",
      "\n",
      "3/500 [====================] 782/782\n",
      "errD_real loss:  0.37  errD_fake loss:  0.53  gen loss:  1.09  acc: 26.64\n",
      "\n",
      "4/500 [====================] 782/782\n",
      "errD_real loss:  0.34  errD_fake loss:  0.52  gen loss:  1.06  acc: 29.24\n",
      "\n",
      "5/500 [====================] 782/782\n",
      "errD_real loss:  0.35  errD_fake loss:  0.54  gen loss:  1.02  acc: 30.39\n",
      "\n",
      "6/500 [====================] 782/782\n",
      "errD_real loss:  0.31  errD_fake loss:  0.53  gen loss:  0.96  acc: 32.90\n",
      "\n",
      "7/500 [====================] 782/782\n",
      "errD_real loss:  0.28  errD_fake loss:  0.53  gen loss:  0.98  acc: 35.71\n",
      "\n",
      "8/500 [====================] 782/782\n",
      "errD_real loss:  0.29  errD_fake loss:  0.55  gen loss:  0.95  acc: 36.94\n",
      "\n",
      "9/500 [====================] 782/782\n",
      "errD_real loss:  0.28  errD_fake loss:  0.57  gen loss:  0.82  acc: 39.06\n",
      "\n",
      "10/500 [====================] 782/782\n",
      "errD_real loss:  0.25  errD_fake loss:  0.57  gen loss:  0.78  acc: 42.33\n",
      "\n",
      "11/500 [====================] 782/782\n",
      "errD_real loss:  0.24  errD_fake loss:  0.57  gen loss:  0.78  acc: 43.19\n",
      "\n",
      "12/500 [====================] 782/782\n",
      "errD_real loss:  0.24  errD_fake loss:  0.57  gen loss:  0.77  acc: 43.79\n",
      "\n",
      "13/500 [====================] 782/782\n",
      "errD_real loss:  0.23  errD_fake loss:  0.57  gen loss:  0.79  acc: 44.34\n",
      "\n",
      "14/500 [====================] 782/782\n",
      "errD_real loss:  0.23  errD_fake loss:  0.57  gen loss:  0.80  acc: 44.65\n",
      "\n",
      "15/500 [====================] 782/782\n",
      "errD_real loss:  0.21  errD_fake loss:  0.56  gen loss:  0.81  acc: 45.90\n",
      "\n",
      "16/500 [====================] 782/782\n",
      "errD_real loss:  0.20  errD_fake loss:  0.56  gen loss:  0.84  acc: 46.28\n",
      "\n",
      "17/500 [====================] 782/782\n",
      "errD_real loss:  0.19  errD_fake loss:  0.55  gen loss:  0.87  acc: 46.62\n",
      "\n",
      "18/500 [====================] 782/782\n",
      "errD_real loss:  0.18  errD_fake loss:  0.54  gen loss:  0.90  acc: 46.68\n",
      "\n",
      "19/500 [====================] 782/782\n",
      "errD_real loss:  0.18  errD_fake loss:  0.54  gen loss:  0.92  acc: 46.90\n",
      "\n",
      "20/500 [====================] 782/782\n",
      "errD_real loss:  0.17  errD_fake loss:  0.54  gen loss:  0.91  acc: 48.14\n",
      "\n",
      "21/500 [====================] 782/782\n",
      "errD_real loss:  0.16  errD_fake loss:  0.53  gen loss:  0.92  acc: 48.13\n",
      "\n",
      "22/500 [====================] 782/782\n",
      "errD_real loss:  0.16  errD_fake loss:  0.54  gen loss:  0.92  acc: 48.31\n",
      "\n",
      "23/500 [====================] 782/782\n",
      "errD_real loss:  0.16  errD_fake loss:  0.54  gen loss:  0.91  acc: 48.57\n",
      "\n",
      "24/500 [====================] 782/782\n",
      "errD_real loss:  0.16  errD_fake loss:  0.54  gen loss:  0.90  acc: 48.32\n",
      "\n",
      "25/500 [====================] 782/782\n",
      "errD_real loss:  0.15  errD_fake loss:  0.53  gen loss:  0.95  acc: 48.73\n",
      "\n",
      "26/500 [====================] 782/782\n",
      "errD_real loss:  0.14  errD_fake loss:  0.53  gen loss:  0.93  acc: 49.60\n",
      "\n",
      "27/500 [====================] 782/782\n",
      "errD_real loss:  0.14  errD_fake loss:  0.53  gen loss:  0.94  acc: 49.14\n",
      "\n",
      "28/500 [====================] 782/782\n",
      "errD_real loss:  0.14  errD_fake loss:  0.52  gen loss:  0.95  acc: 49.58\n",
      "\n",
      "29/500 [====================] 782/782\n",
      "errD_real loss:  0.13  errD_fake loss:  0.52  gen loss:  0.98  acc: 49.81\n",
      "\n",
      "30/500 [====================] 782/782\n",
      "errD_real loss:  0.13  errD_fake loss:  0.52  gen loss:  0.97  acc: 49.86\n",
      "\n",
      "31/500 [====================] 782/782\n",
      "errD_real loss:  0.12  errD_fake loss:  0.51  gen loss:  0.99  acc: 50.47\n",
      "\n",
      "32/500 [====================] 782/782\n",
      "errD_real loss:  0.11  errD_fake loss:  0.51  gen loss:  1.03  acc: 50.40\n",
      "\n",
      "33/500 [====================] 782/782\n",
      "errD_real loss:  0.11  errD_fake loss:  0.51  gen loss:  1.03  acc: 50.28\n",
      "\n",
      "34/500 [====================] 782/782\n",
      "errD_real loss:  0.09  errD_fake loss:  0.50  gen loss:  1.05  acc: 51.01\n",
      "\n",
      "35/500 [====================] 782/782\n",
      "errD_real loss:  0.10  errD_fake loss:  0.50  gen loss:  1.05  acc: 50.54\n",
      "\n",
      "36/500 [====================] 782/782\n",
      "errD_real loss:  0.10  errD_fake loss:  0.50  gen loss:  1.05  acc: 50.52\n",
      "\n",
      "37/500 [====================] 782/782\n",
      "errD_real loss:  0.09  errD_fake loss:  0.48  gen loss:  1.08  acc: 50.96\n",
      "\n",
      "38/500 [====================] 782/782\n",
      "errD_real loss:  0.10  errD_fake loss:  0.51  gen loss:  1.06  acc: 50.98\n",
      "\n",
      "39/500 [====================] 782/782\n",
      "errD_real loss:  0.08  errD_fake loss:  0.50  gen loss:  1.04  acc: 51.51\n",
      "\n",
      "40/500 [====================] 782/782\n",
      "errD_real loss:  0.08  errD_fake loss:  0.49  gen loss:  1.07  acc: 51.30\n",
      "\n",
      "41/500 [====================] 782/782\n",
      "errD_real loss:  0.08  errD_fake loss:  0.48  gen loss:  1.09  acc: 51.38\n",
      "\n",
      "42/500 [====================] 782/782\n",
      "errD_real loss:  0.08  errD_fake loss:  0.49  gen loss:  1.09  acc: 51.15\n",
      "\n",
      "43/500 [====================] 782/782\n",
      "errD_real loss:  0.07  errD_fake loss:  0.48  gen loss:  1.11  acc: 51.40\n",
      "\n",
      "44/500 [====================] 782/782\n",
      "errD_real loss:  0.08  errD_fake loss:  0.49  gen loss:  1.10  acc: 51.70\n",
      "\n",
      "45/500 [====================] 782/782\n",
      "errD_real loss:  0.08  errD_fake loss:  0.49  gen loss:  1.11  acc: 51.56\n",
      "\n",
      "46/500 [====================] 782/782\n",
      "errD_real loss:  0.06  errD_fake loss:  0.47  gen loss:  1.14  acc: 51.81\n",
      "\n",
      "47/500 [====================] 782/782\n",
      "errD_real loss:  0.07  errD_fake loss:  0.48  gen loss:  1.14  acc: 52.00\n",
      "\n",
      "48/500 [====================] 782/782\n",
      "errD_real loss:  0.07  errD_fake loss:  0.49  gen loss:  1.14  acc: 51.82\n",
      "\n",
      "49/500 [====================] 782/782\n",
      "errD_real loss:  0.08  errD_fake loss:  0.49  gen loss:  1.08  acc: 51.79\n",
      "\n",
      "50/500 [====================] 782/782\n",
      "errD_real loss:  0.06  errD_fake loss:  0.47  gen loss:  1.14  acc: 52.06\n",
      "\n",
      "51/500 [====================] 782/782\n",
      "errD_real loss:  0.05  errD_fake loss:  0.47  gen loss:  1.17  acc: 51.90\n",
      "\n",
      "52/500 [====================] 782/782\n",
      "errD_real loss:  0.06  errD_fake loss:  0.47  gen loss:  1.16  acc: 52.16\n",
      "\n",
      "53/500 [====================] 782/782\n",
      "errD_real loss:  0.07  errD_fake loss:  0.48  gen loss:  1.12  acc: 52.36\n",
      "\n",
      "54/500 [====================] 782/782\n",
      "errD_real loss:  0.07  errD_fake loss:  0.48  gen loss:  1.13  acc: 52.39\n",
      "\n",
      "55/500 [====================] 782/782\n",
      "errD_real loss:  0.05  errD_fake loss:  0.47  gen loss:  1.14  acc: 52.49\n",
      "\n",
      "56/500 [====================] 782/782\n",
      "errD_real loss:  0.06  errD_fake loss:  0.48  gen loss:  1.14  acc: 52.65\n",
      "\n",
      "57/500 [====================] 782/782\n",
      "errD_real loss:  0.05  errD_fake loss:  0.47  gen loss:  1.16  acc: 52.34\n",
      "\n",
      "58/500 [====================] 782/782\n",
      "errD_real loss:  0.05  errD_fake loss:  0.47  gen loss:  1.14  acc: 52.46\n",
      "\n",
      "59/500 [====================] 782/782\n",
      "errD_real loss:  0.06  errD_fake loss:  0.49  gen loss:  1.11  acc: 52.74\n",
      "\n",
      "60/500 [====================] 782/782\n",
      "errD_real loss:  0.06  errD_fake loss:  0.47  gen loss:  1.14  acc: 52.60\n",
      "\n",
      "61/500 [====================] 782/782\n",
      "errD_real loss:  0.05  errD_fake loss:  0.47  gen loss:  1.12  acc: 53.03\n",
      "\n",
      "62/500 [====================] 782/782\n",
      "errD_real loss:  0.05  errD_fake loss:  0.48  gen loss:  1.10  acc: 52.88\n",
      "\n",
      "63/500 [====================] 782/782\n",
      "errD_real loss:  0.06  errD_fake loss:  0.48  gen loss:  1.11  acc: 52.95\n",
      "\n",
      "64/500 [====================] 782/782\n",
      "errD_real loss:  0.06  errD_fake loss:  0.49  gen loss:  1.11  acc: 52.91\n",
      "\n",
      "65/500 [====================] 782/782\n",
      "errD_real loss:  0.06  errD_fake loss:  0.48  gen loss:  1.09  acc: 53.32\n",
      "\n",
      "66/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.46  gen loss:  1.18  acc: 52.95\n",
      "\n",
      "67/500 [====================] 782/782\n",
      "errD_real loss:  0.03  errD_fake loss:  0.47  gen loss:  1.14  acc: 53.31\n",
      "\n",
      "68/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.47  gen loss:  1.17  acc: 53.25\n",
      "\n",
      "69/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.47  gen loss:  1.12  acc: 52.97\n",
      "\n",
      "70/500 [====================] 782/782\n",
      "errD_real loss:  0.05  errD_fake loss:  0.48  gen loss:  1.11  acc: 53.61\n",
      "\n",
      "71/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.48  gen loss:  1.15  acc: 53.62\n",
      "\n",
      "72/500 [====================] 782/782\n",
      "errD_real loss:  0.05  errD_fake loss:  0.48  gen loss:  1.12  acc: 53.75\n",
      "\n",
      "73/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.47  gen loss:  1.17  acc: 53.83\n",
      "\n",
      "74/500 [====================] 782/782\n",
      "errD_real loss:  0.05  errD_fake loss:  0.47  gen loss:  1.11  acc: 53.92\n",
      "\n",
      "75/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.47  gen loss:  1.10  acc: 53.99\n",
      "\n",
      "76/500 [====================] 782/782\n",
      "errD_real loss:  0.05  errD_fake loss:  0.49  gen loss:  1.09  acc: 54.02\n",
      "\n",
      "77/500 [====================] 782/782\n",
      "errD_real loss:  0.05  errD_fake loss:  0.48  gen loss:  1.11  acc: 53.87\n",
      "\n",
      "78/500 [====================] 782/782\n",
      "errD_real loss:  0.05  errD_fake loss:  0.49  gen loss:  1.11  acc: 54.02\n",
      "\n",
      "79/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.48  gen loss:  1.11  acc: 54.04\n",
      "\n",
      "80/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.48  gen loss:  1.07  acc: 54.52\n",
      "\n",
      "81/500 [====================] 782/782\n",
      "errD_real loss:  0.05  errD_fake loss:  0.48  gen loss:  1.07  acc: 54.16\n",
      "\n",
      "82/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.47  gen loss:  1.10  acc: 54.06\n",
      "\n",
      "83/500 [====================] 782/782\n",
      "errD_real loss:  0.05  errD_fake loss:  0.49  gen loss:  1.07  acc: 54.30\n",
      "\n",
      "84/500 [====================] 782/782\n",
      "errD_real loss:  0.05  errD_fake loss:  0.48  gen loss:  1.11  acc: 54.08\n",
      "\n",
      "85/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.48  gen loss:  1.09  acc: 54.66\n",
      "\n",
      "86/500 [====================] 782/782\n",
      "errD_real loss:  0.05  errD_fake loss:  0.48  gen loss:  1.08  acc: 54.69\n",
      "\n",
      "87/500 [====================] 782/782\n",
      "errD_real loss:  0.03  errD_fake loss:  0.48  gen loss:  1.11  acc: 54.62\n",
      "\n",
      "88/500 [====================] 782/782\n",
      "errD_real loss:  0.05  errD_fake loss:  0.49  gen loss:  1.09  acc: 54.35\n",
      "\n",
      "89/500 [====================] 782/782\n",
      "errD_real loss:  0.03  errD_fake loss:  0.48  gen loss:  1.11  acc: 54.42\n",
      "\n",
      "90/500 [====================] 782/782\n",
      "errD_real loss:  0.03  errD_fake loss:  0.47  gen loss:  1.12  acc: 54.56\n",
      "\n",
      "91/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.47  gen loss:  1.10  acc: 54.41\n",
      "\n",
      "92/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.48  gen loss:  1.10  acc: 54.35\n",
      "\n",
      "93/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.48  gen loss:  1.09  acc: 54.72\n",
      "\n",
      "94/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.49  gen loss:  1.09  acc: 54.76\n",
      "\n",
      "95/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.48  gen loss:  1.07  acc: 54.72\n",
      "\n",
      "96/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.48  gen loss:  1.11  acc: 54.86\n",
      "\n",
      "97/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.48  gen loss:  1.09  acc: 55.05\n",
      "\n",
      "98/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.49  gen loss:  1.07  acc: 55.20\n",
      "\n",
      "99/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.49  gen loss:  1.06  acc: 54.98\n",
      "\n",
      "100/500 [====================] 782/782\n",
      "errD_real loss:  0.03  errD_fake loss:  0.48  gen loss:  1.08  acc: 54.85\n",
      "\n",
      "101/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.48  gen loss:  1.11  acc: 55.30\n",
      "\n",
      "102/500 [====================] 782/782\n",
      "errD_real loss:  0.03  errD_fake loss:  0.48  gen loss:  1.10  acc: 55.11\n",
      "\n",
      "103/500 [====================] 782/782\n",
      "errD_real loss:  0.03  errD_fake loss:  0.48  gen loss:  1.10  acc: 55.09\n",
      "\n",
      "104/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.48  gen loss:  1.10  acc: 55.25\n",
      "\n",
      "105/500 [====================] 782/782\n",
      "errD_real loss:  0.02  errD_fake loss:  0.47  gen loss:  1.11  acc: 55.54\n",
      "\n",
      "106/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.48  gen loss:  1.07  acc: 55.26\n",
      "\n",
      "107/500 [====================] 782/782\n",
      "errD_real loss:  0.04  errD_fake loss:  0.49  gen loss:  1.06  acc: 55.47\n",
      "\n",
      "108/500 [====================] 782/782\n",
      "errD_real loss:  0.02  errD_fake loss:  0.48  gen loss:  1.11  acc: 55.60\n",
      "\n",
      "109/500 [====================] 782/782\n",
      "errD_real loss:  0.03  errD_fake loss:  0.48  gen loss:  1.07  acc: 55.53\n",
      "\n",
      "110/500 [====================] 782/782\n",
      "errD_real loss:  0.03  errD_fake loss:  0.48  gen loss:  1.07  acc: 55.52\n",
      "\n",
      "111/500 [====================] 782/782\n",
      "errD_real loss:  0.03  errD_fake loss:  0.48  gen loss:  1.10  acc: 55.57\n",
      "\n",
      "112/500 [====================] 782/782\n",
      "errD_real loss:  0.03  errD_fake loss:  0.48  gen loss:  1.08  acc: 55.46\n",
      "\n",
      "113/500 [====================] 782/782\n",
      "errD_real loss:  0.02  errD_fake loss:  0.47  gen loss:  1.15  acc: 55.77\n",
      "\n",
      "114/500 [====================] 782/782\n",
      "errD_real loss:  0.02  errD_fake loss:  0.47  gen loss:  1.12  acc: 55.86\n",
      "\n",
      "115/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.12  acc: 55.73\n",
      "\n",
      "116/500 [====================] 782/782\n",
      "errD_real loss:  0.02  errD_fake loss:  0.47  gen loss:  1.11  acc: 55.90\n",
      "\n",
      "117/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.10  acc: 55.84\n",
      "\n",
      "118/500 [====================] 782/782\n",
      "errD_real loss:  0.02  errD_fake loss:  0.47  gen loss:  1.11  acc: 55.62\n",
      "\n",
      "119/500 [====================] 782/782\n",
      "errD_real loss:  0.02  errD_fake loss:  0.47  gen loss:  1.12  acc: 55.92\n",
      "\n",
      "120/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.12  acc: 55.97\n",
      "\n",
      "121/500 [====================] 782/782\n",
      "errD_real loss:  0.02  errD_fake loss:  0.48  gen loss:  1.15  acc: 55.66\n",
      "\n",
      "122/500 [====================] 782/782\n",
      "errD_real loss:  0.02  errD_fake loss:  0.48  gen loss:  1.11  acc: 56.41\n",
      "\n",
      "123/500 [====================] 782/782\n",
      "errD_real loss:  0.02  errD_fake loss:  0.48  gen loss:  1.10  acc: 56.08\n",
      "\n",
      "124/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.46  gen loss:  1.14  acc: 55.86\n",
      "\n",
      "125/500 [====================] 782/782\n",
      "errD_real loss:  0.03  errD_fake loss:  0.49  gen loss:  1.09  acc: 56.22\n",
      "\n",
      "126/500 [====================] 782/782\n",
      "errD_real loss:  0.02  errD_fake loss:  0.48  gen loss:  1.08  acc: 56.11\n",
      "\n",
      "127/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.10  acc: 56.19\n",
      "\n",
      "128/500 [====================] 782/782\n",
      "errD_real loss:  0.03  errD_fake loss:  0.48  gen loss:  1.08  acc: 56.05\n",
      "\n",
      "129/500 [====================] 782/782\n",
      "errD_real loss:  0.02  errD_fake loss:  0.48  gen loss:  1.07  acc: 56.21\n",
      "\n",
      "130/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.07  acc: 56.27\n",
      "\n",
      "131/500 [====================] 782/782\n",
      "errD_real loss:  0.02  errD_fake loss:  0.48  gen loss:  1.07  acc: 56.42\n",
      "\n",
      "132/500 [====================] 782/782\n",
      "errD_real loss:  0.02  errD_fake loss:  0.48  gen loss:  1.11  acc: 56.68\n",
      "\n",
      "133/500 [====================] 782/782\n",
      "errD_real loss:  0.02  errD_fake loss:  0.48  gen loss:  1.08  acc: 56.29\n",
      "\n",
      "134/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.12  acc: 56.45\n",
      "\n",
      "135/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.13  acc: 56.54\n",
      "\n",
      "136/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.14  acc: 56.20\n",
      "\n",
      "137/500 [====================] 782/782\n",
      "errD_real loss:  0.00  errD_fake loss:  0.47  gen loss:  1.14  acc: 56.81\n",
      "\n",
      "138/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.08  acc: 56.43\n",
      "\n",
      "139/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.14  acc: 56.76\n",
      "\n",
      "140/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.14  acc: 56.73\n",
      "\n",
      "141/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.46  gen loss:  1.12  acc: 56.79\n",
      "\n",
      "142/500 [====================] 782/782\n",
      "errD_real loss:  0.00  errD_fake loss:  0.47  gen loss:  1.11  acc: 56.89\n",
      "\n",
      "143/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.15  acc: 56.60\n",
      "\n",
      "144/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.13  acc: 56.71\n",
      "\n",
      "145/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.10  acc: 56.95\n",
      "\n",
      "146/500 [====================] 782/782\n",
      "errD_real loss: -0.00  errD_fake loss:  0.47  gen loss:  1.16  acc: 56.93\n",
      "\n",
      "147/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.11  acc: 57.04\n",
      "\n",
      "148/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.48  gen loss:  1.11  acc: 56.79\n",
      "\n",
      "149/500 [====================] 782/782\n",
      "errD_real loss:  0.00  errD_fake loss:  0.47  gen loss:  1.14  acc: 57.21\n",
      "\n",
      "150/500 [====================] 782/782\n",
      "errD_real loss:  0.00  errD_fake loss:  0.47  gen loss:  1.15  acc: 56.57\n",
      "\n",
      "151/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.48  gen loss:  1.09  acc: 57.36\n",
      "\n",
      "152/500 [====================] 782/782\n",
      "errD_real loss: -0.00  errD_fake loss:  0.46  gen loss:  1.16  acc: 56.85\n",
      "\n",
      "153/500 [====================] 782/782\n",
      "errD_real loss:  0.00  errD_fake loss:  0.47  gen loss:  1.12  acc: 56.86\n",
      "\n",
      "154/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.11  acc: 56.94\n",
      "\n",
      "155/500 [====================] 782/782\n",
      "errD_real loss:  0.00  errD_fake loss:  0.47  gen loss:  1.12  acc: 57.13\n",
      "\n",
      "156/500 [====================] 782/782\n",
      "errD_real loss: -0.00  errD_fake loss:  0.47  gen loss:  1.10  acc: 57.04\n",
      "\n",
      "157/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.46  gen loss:  1.18  acc: 57.19\n",
      "\n",
      "158/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.10  acc: 57.08\n",
      "\n",
      "159/500 [====================] 782/782\n",
      "errD_real loss:  0.00  errD_fake loss:  0.47  gen loss:  1.14  acc: 57.24\n",
      "\n",
      "160/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.46  gen loss:  1.14  acc: 57.29\n",
      "\n",
      "161/500 [====================] 782/782\n",
      "errD_real loss:  0.00  errD_fake loss:  0.46  gen loss:  1.12  acc: 57.33\n",
      "\n",
      "162/500 [====================] 782/782\n",
      "errD_real loss: -0.00  errD_fake loss:  0.47  gen loss:  1.14  acc: 57.31\n",
      "\n",
      "163/500 [====================] 782/782\n",
      "errD_real loss: -0.00  errD_fake loss:  0.47  gen loss:  1.14  acc: 57.25\n",
      "\n",
      "164/500 [====================] 782/782\n",
      "errD_real loss: -0.00  errD_fake loss:  0.46  gen loss:  1.16  acc: 57.48\n",
      "\n",
      "165/500 [====================] 782/782\n",
      "errD_real loss:  0.00  errD_fake loss:  0.47  gen loss:  1.11  acc: 57.44\n",
      "\n",
      "166/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.46  gen loss:  1.13  acc: 57.49\n",
      "\n",
      "167/500 [====================] 782/782\n",
      "errD_real loss: -0.00  errD_fake loss:  0.47  gen loss:  1.14  acc: 57.47\n",
      "\n",
      "168/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.49  gen loss:  1.09  acc: 57.35\n",
      "\n",
      "169/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.46  gen loss:  1.16  acc: 57.49\n",
      "\n",
      "170/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.46  gen loss:  1.16  acc: 57.59\n",
      "\n",
      "171/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.46  gen loss:  1.11  acc: 57.37\n",
      "\n",
      "172/500 [====================] 782/782\n",
      "errD_real loss: -0.00  errD_fake loss:  0.47  gen loss:  1.18  acc: 57.18\n",
      "\n",
      "173/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.45  gen loss:  1.14  acc: 57.53\n",
      "\n",
      "174/500 [====================] 782/782\n",
      "errD_real loss:  0.01  errD_fake loss:  0.47  gen loss:  1.12  acc: 57.81\n",
      "\n",
      "175/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.46  gen loss:  1.18  acc: 57.78\n",
      "\n",
      "176/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.46  gen loss:  1.12  acc: 57.65\n",
      "\n",
      "177/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.46  gen loss:  1.17  acc: 57.53\n",
      "\n",
      "178/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.47  gen loss:  1.15  acc: 57.68\n",
      "\n",
      "179/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.45  gen loss:  1.17  acc: 57.63\n",
      "\n",
      "180/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.47  gen loss:  1.15  acc: 57.53\n",
      "\n",
      "181/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.46  gen loss:  1.14  acc: 57.60\n",
      "\n",
      "182/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.47  gen loss:  1.17  acc: 57.78\n",
      "\n",
      "183/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.45  gen loss:  1.14  acc: 57.64\n",
      "\n",
      "184/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.46  gen loss:  1.14  acc: 57.56\n",
      "\n",
      "185/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.46  gen loss:  1.16  acc: 57.84\n",
      "\n",
      "186/500 [====================] 782/782\n",
      "errD_real loss: -0.00  errD_fake loss:  0.47  gen loss:  1.12  acc: 57.58\n",
      "\n",
      "187/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.46  gen loss:  1.21  acc: 57.80\n",
      "\n",
      "188/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.46  gen loss:  1.14  acc: 57.83\n",
      "\n",
      "189/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.47  gen loss:  1.13  acc: 58.08\n",
      "\n",
      "190/500 [====================] 782/782\n",
      "errD_real loss: -0.00  errD_fake loss:  0.46  gen loss:  1.13  acc: 57.83\n",
      "\n",
      "191/500 [====================] 782/782\n",
      "errD_real loss:  0.00  errD_fake loss:  0.47  gen loss:  1.09  acc: 57.96\n",
      "\n",
      "192/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.47  gen loss:  1.17  acc: 57.87\n",
      "\n",
      "193/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.16  acc: 57.85\n",
      "\n",
      "194/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.47  gen loss:  1.16  acc: 58.14\n",
      "\n",
      "195/500 [====================] 782/782\n",
      "errD_real loss:  0.00  errD_fake loss:  0.47  gen loss:  1.13  acc: 57.86\n",
      "\n",
      "196/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.46  gen loss:  1.08  acc: 57.81\n",
      "\n",
      "197/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.46  gen loss:  1.15  acc: 57.59\n",
      "\n",
      "198/500 [====================] 782/782\n",
      "errD_real loss: -0.00  errD_fake loss:  0.47  gen loss:  1.09  acc: 58.01\n",
      "\n",
      "199/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.46  gen loss:  1.13  acc: 58.11\n",
      "\n",
      "200/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.46  gen loss:  1.15  acc: 57.73\n",
      "\n",
      "201/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.46  gen loss:  1.14  acc: 58.19\n",
      "\n",
      "202/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.19  acc: 57.99\n",
      "\n",
      "203/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.46  gen loss:  1.15  acc: 58.16\n",
      "\n",
      "204/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.46  gen loss:  1.17  acc: 58.05\n",
      "\n",
      "205/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.46  gen loss:  1.15  acc: 58.32\n",
      "\n",
      "206/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.45  gen loss:  1.15  acc: 58.12\n",
      "\n",
      "207/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.46  gen loss:  1.17  acc: 58.14\n",
      "\n",
      "208/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.46  gen loss:  1.18  acc: 57.91\n",
      "\n",
      "209/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.18  acc: 58.53\n",
      "\n",
      "210/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.46  gen loss:  1.16  acc: 58.14\n",
      "\n",
      "211/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.46  gen loss:  1.16  acc: 57.96\n",
      "\n",
      "212/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.46  gen loss:  1.15  acc: 58.07\n",
      "\n",
      "213/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.45  gen loss:  1.21  acc: 58.32\n",
      "\n",
      "214/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.46  gen loss:  1.20  acc: 58.13\n",
      "\n",
      "215/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.45  gen loss:  1.17  acc: 58.14\n",
      "\n",
      "216/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.46  gen loss:  1.19  acc: 58.38\n",
      "\n",
      "217/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.47  gen loss:  1.18  acc: 57.91\n",
      "\n",
      "218/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.19  acc: 58.32\n",
      "\n",
      "219/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.19  acc: 58.38\n",
      "\n",
      "220/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.21  acc: 58.42\n",
      "\n",
      "221/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.20  acc: 58.41\n",
      "\n",
      "222/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.17  acc: 58.42\n",
      "\n",
      "223/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.19  acc: 58.42\n",
      "\n",
      "224/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.46  gen loss:  1.21  acc: 58.39\n",
      "\n",
      "225/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.46  gen loss:  1.15  acc: 58.64\n",
      "\n",
      "226/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.17  acc: 58.62\n",
      "\n",
      "227/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.19  acc: 58.60\n",
      "\n",
      "228/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.46  gen loss:  1.20  acc: 58.62\n",
      "\n",
      "229/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.46  gen loss:  1.18  acc: 58.20\n",
      "\n",
      "230/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.46  gen loss:  1.15  acc: 58.63\n",
      "\n",
      "231/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.20  acc: 58.30\n",
      "\n",
      "232/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.44  gen loss:  1.21  acc: 58.50\n",
      "\n",
      "233/500 [====================] 782/782\n",
      "errD_real loss: -0.01  errD_fake loss:  0.47  gen loss:  1.19  acc: 58.53\n",
      "\n",
      "234/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.46  gen loss:  1.18  acc: 58.58\n",
      "\n",
      "235/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.19  acc: 58.54\n",
      "\n",
      "236/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.44  gen loss:  1.19  acc: 58.82\n",
      "\n",
      "237/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.18  acc: 58.93\n",
      "\n",
      "238/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.44  gen loss:  1.18  acc: 58.51\n",
      "\n",
      "239/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.46  gen loss:  1.17  acc: 58.79\n",
      "\n",
      "240/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.44  gen loss:  1.21  acc: 58.55\n",
      "\n",
      "241/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.47  gen loss:  1.14  acc: 58.44\n",
      "\n",
      "242/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.47  gen loss:  1.15  acc: 58.71\n",
      "\n",
      "243/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.45  gen loss:  1.22  acc: 58.51\n",
      "\n",
      "244/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.21  acc: 58.92\n",
      "\n",
      "245/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.20  acc: 58.86\n",
      "\n",
      "246/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.18  acc: 58.48\n",
      "\n",
      "247/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.19  acc: 58.83\n",
      "\n",
      "248/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.46  gen loss:  1.20  acc: 58.50\n",
      "\n",
      "249/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.20  acc: 59.03\n",
      "\n",
      "250/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.17  acc: 58.37\n",
      "\n",
      "251/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.44  gen loss:  1.20  acc: 58.83\n",
      "\n",
      "252/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.21  acc: 58.96\n",
      "\n",
      "253/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.46  gen loss:  1.16  acc: 58.75\n",
      "\n",
      "254/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.17  acc: 59.15\n",
      "\n",
      "255/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.17  acc: 58.68\n",
      "\n",
      "256/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.20  acc: 58.74\n",
      "\n",
      "257/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.24  acc: 58.80\n",
      "\n",
      "258/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.44  gen loss:  1.22  acc: 58.57\n",
      "\n",
      "259/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.46  gen loss:  1.15  acc: 58.84\n",
      "\n",
      "260/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.21  acc: 58.94\n",
      "\n",
      "261/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.44  gen loss:  1.25  acc: 58.77\n",
      "\n",
      "262/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.46  gen loss:  1.19  acc: 58.95\n",
      "\n",
      "263/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.44  gen loss:  1.18  acc: 58.95\n",
      "\n",
      "264/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.21  acc: 58.98\n",
      "\n",
      "265/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.46  gen loss:  1.18  acc: 59.00\n",
      "\n",
      "266/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.47  gen loss:  1.14  acc: 59.03\n",
      "\n",
      "267/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.46  gen loss:  1.19  acc: 59.11\n",
      "\n",
      "268/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.18  acc: 59.23\n",
      "\n",
      "269/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.46  gen loss:  1.17  acc: 58.89\n",
      "\n",
      "270/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.23  acc: 58.97\n",
      "\n",
      "271/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.19  acc: 58.89\n",
      "\n",
      "272/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.16  acc: 59.01\n",
      "\n",
      "273/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.17  acc: 59.20\n",
      "\n",
      "274/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.24  acc: 58.91\n",
      "\n",
      "275/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.46  gen loss:  1.20  acc: 59.06\n",
      "\n",
      "276/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.43  gen loss:  1.19  acc: 58.91\n",
      "\n",
      "277/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.17  acc: 58.95\n",
      "\n",
      "278/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.24  acc: 59.13\n",
      "\n",
      "279/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.27  acc: 59.18\n",
      "\n",
      "280/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.19  acc: 58.89\n",
      "\n",
      "281/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.21  acc: 59.24\n",
      "\n",
      "282/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.21  acc: 58.99\n",
      "\n",
      "283/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.20  acc: 59.46\n",
      "\n",
      "284/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.24  acc: 58.96\n",
      "\n",
      "285/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.17  acc: 59.31\n",
      "\n",
      "286/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.46  gen loss:  1.21  acc: 58.98\n",
      "\n",
      "287/500 [====================] 782/782\n",
      "errD_real loss: -0.02  errD_fake loss:  0.47  gen loss:  1.17  acc: 58.93\n",
      "\n",
      "288/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.44  gen loss:  1.14  acc: 59.23\n",
      "\n",
      "289/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.44  gen loss:  1.24  acc: 59.01\n",
      "\n",
      "290/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.44  gen loss:  1.18  acc: 59.13\n",
      "\n",
      "291/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.17  acc: 59.23\n",
      "\n",
      "292/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.43  gen loss:  1.22  acc: 59.26\n",
      "\n",
      "293/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.23  acc: 59.21\n",
      "\n",
      "294/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.18  acc: 58.94\n",
      "\n",
      "295/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.23  acc: 59.11\n",
      "\n",
      "296/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.46  gen loss:  1.19  acc: 59.07\n",
      "\n",
      "297/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.24  acc: 59.40\n",
      "\n",
      "298/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.45  gen loss:  1.23  acc: 59.13\n",
      "\n",
      "299/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.21  acc: 59.27\n",
      "\n",
      "300/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.16  acc: 59.22\n",
      "\n",
      "301/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.17  acc: 59.75\n",
      "\n",
      "302/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.25  acc: 59.59\n",
      "\n",
      "303/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.46  gen loss:  1.23  acc: 59.50\n",
      "\n",
      "304/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.22  acc: 59.39\n",
      "\n",
      "305/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.19  acc: 59.30\n",
      "\n",
      "306/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.24  acc: 59.65\n",
      "\n",
      "307/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.23  acc: 59.21\n",
      "\n",
      "308/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.44  gen loss:  1.17  acc: 59.19\n",
      "\n",
      "309/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.21  acc: 59.08\n",
      "\n",
      "310/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.44  gen loss:  1.20  acc: 59.29\n",
      "\n",
      "311/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.19  acc: 59.53\n",
      "\n",
      "312/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.23  acc: 59.51\n",
      "\n",
      "313/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.43  gen loss:  1.24  acc: 59.29\n",
      "\n",
      "314/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.21  acc: 59.36\n",
      "\n",
      "315/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.42  gen loss:  1.22  acc: 59.41\n",
      "\n",
      "316/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.25  acc: 59.39\n",
      "\n",
      "317/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.19  acc: 59.58\n",
      "\n",
      "318/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.24  acc: 59.67\n",
      "\n",
      "319/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.19  acc: 59.80\n",
      "\n",
      "320/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.20  acc: 59.55\n",
      "\n",
      "321/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.22  acc: 59.63\n",
      "\n",
      "322/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.18  acc: 59.81\n",
      "\n",
      "323/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.22  acc: 59.54\n",
      "\n",
      "324/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.26  acc: 59.49\n",
      "\n",
      "325/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.20  acc: 59.46\n",
      "\n",
      "326/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.22  acc: 59.41\n",
      "\n",
      "327/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.19  acc: 59.54\n",
      "\n",
      "328/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.46  gen loss:  1.22  acc: 59.45\n",
      "\n",
      "329/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.24  acc: 59.24\n",
      "\n",
      "330/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.24  acc: 59.53\n",
      "\n",
      "331/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.46  gen loss:  1.22  acc: 59.89\n",
      "\n",
      "332/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.44  gen loss:  1.25  acc: 59.64\n",
      "\n",
      "333/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.44  gen loss:  1.20  acc: 59.62\n",
      "\n",
      "334/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.19  acc: 59.62\n",
      "\n",
      "335/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.46  gen loss:  1.18  acc: 59.50\n",
      "\n",
      "336/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.23  acc: 59.31\n",
      "\n",
      "337/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.27  acc: 59.95\n",
      "\n",
      "338/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.20  acc: 59.75\n",
      "\n",
      "339/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.20  acc: 59.59\n",
      "\n",
      "340/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.31  acc: 59.65\n",
      "\n",
      "341/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.24  acc: 59.78\n",
      "\n",
      "342/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.23  acc: 59.75\n",
      "\n",
      "343/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.23  acc: 59.77\n",
      "\n",
      "344/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.24  acc: 59.81\n",
      "\n",
      "345/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.30  acc: 59.85\n",
      "\n",
      "346/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.21  acc: 59.93\n",
      "\n",
      "347/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.26  acc: 59.47\n",
      "\n",
      "348/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.27  acc: 59.89\n",
      "\n",
      "349/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.24  acc: 59.85\n",
      "\n",
      "350/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.43  gen loss:  1.20  acc: 59.81\n",
      "\n",
      "351/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.44  gen loss:  1.27  acc: 59.67\n",
      "\n",
      "352/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.25  acc: 59.84\n",
      "\n",
      "353/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.17  acc: 60.01\n",
      "\n",
      "354/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.24  acc: 59.60\n",
      "\n",
      "355/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.23  acc: 59.76\n",
      "\n",
      "356/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.42  gen loss:  1.28  acc: 59.62\n",
      "\n",
      "357/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.26  acc: 59.80\n",
      "\n",
      "358/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.22  acc: 59.81\n",
      "\n",
      "359/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.20  acc: 59.75\n",
      "\n",
      "360/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.26  acc: 59.88\n",
      "\n",
      "361/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.23  acc: 59.80\n",
      "\n",
      "362/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.21  acc: 59.87\n",
      "\n",
      "363/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.25  acc: 59.84\n",
      "\n",
      "364/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.23  acc: 60.00\n",
      "\n",
      "365/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.20  acc: 59.87\n",
      "\n",
      "366/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.23  acc: 59.83\n",
      "\n",
      "367/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.22  acc: 59.87\n",
      "\n",
      "368/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.17  acc: 60.06\n",
      "\n",
      "369/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.42  gen loss:  1.30  acc: 60.01\n",
      "\n",
      "370/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.25  acc: 60.01\n",
      "\n",
      "371/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.29  acc: 60.04\n",
      "\n",
      "372/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.43  gen loss:  1.28  acc: 59.91\n",
      "\n",
      "373/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.23  acc: 59.80\n",
      "\n",
      "374/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.27  acc: 60.05\n",
      "\n",
      "375/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.22  acc: 59.79\n",
      "\n",
      "376/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.28  acc: 60.02\n",
      "\n",
      "377/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.26  acc: 59.89\n",
      "\n",
      "378/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.30  acc: 59.64\n",
      "\n",
      "379/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.24  acc: 60.27\n",
      "\n",
      "380/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.25  acc: 59.88\n",
      "\n",
      "381/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.42  gen loss:  1.27  acc: 59.89\n",
      "\n",
      "382/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.26  acc: 59.93\n",
      "\n",
      "383/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.23  acc: 59.94\n",
      "\n",
      "384/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.23  acc: 60.29\n",
      "\n",
      "385/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.44  gen loss:  1.26  acc: 59.83\n",
      "\n",
      "386/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.24  acc: 60.10\n",
      "\n",
      "387/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.42  gen loss:  1.29  acc: 59.95\n",
      "\n",
      "388/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.26  acc: 60.16\n",
      "\n",
      "389/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.21  acc: 59.78\n",
      "\n",
      "390/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.23  acc: 60.09\n",
      "\n",
      "391/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.25  acc: 60.12\n",
      "\n",
      "392/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.24  acc: 60.08\n",
      "\n",
      "393/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.29  acc: 59.90\n",
      "\n",
      "394/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.27  acc: 59.82\n",
      "\n",
      "395/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.25  acc: 60.19\n",
      "\n",
      "396/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.44  gen loss:  1.22  acc: 60.09\n",
      "\n",
      "397/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.28  acc: 59.98\n",
      "\n",
      "398/500 [====================] 782/782\n",
      "errD_real loss: -0.04  errD_fake loss:  0.45  gen loss:  1.19  acc: 59.99\n",
      "\n",
      "399/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.26  acc: 60.06\n",
      "\n",
      "400/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.29  acc: 59.81\n",
      "\n",
      "401/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.26  acc: 60.17\n",
      "\n",
      "402/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.45  gen loss:  1.22  acc: 60.00\n",
      "\n",
      "403/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.25  acc: 60.00\n",
      "\n",
      "404/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.25  acc: 59.98\n",
      "\n",
      "405/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.42  gen loss:  1.27  acc: 60.43\n",
      "\n",
      "406/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.24  acc: 60.06\n",
      "\n",
      "407/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.46  gen loss:  1.17  acc: 60.31\n",
      "\n",
      "408/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.22  acc: 59.85\n",
      "\n",
      "409/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.26  acc: 60.11\n",
      "\n",
      "410/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.23  acc: 60.23\n",
      "\n",
      "411/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.26  acc: 60.28\n",
      "\n",
      "412/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.43  gen loss:  1.21  acc: 59.97\n",
      "\n",
      "413/500 [====================] 782/782\n",
      "errD_real loss: -0.03  errD_fake loss:  0.46  gen loss:  1.23  acc: 60.17\n",
      "\n",
      "414/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.20  acc: 60.34\n",
      "\n",
      "415/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.18  acc: 59.95\n",
      "\n",
      "416/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.28  acc: 60.21\n",
      "\n",
      "417/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.25  acc: 60.23\n",
      "\n",
      "418/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.23  acc: 60.27\n",
      "\n",
      "419/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.43  gen loss:  1.26  acc: 60.46\n",
      "\n",
      "420/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.28  acc: 60.46\n",
      "\n",
      "421/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.25  acc: 60.20\n",
      "\n",
      "422/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.20  acc: 60.17\n",
      "\n",
      "423/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.23  acc: 60.26\n",
      "\n",
      "424/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.44  gen loss:  1.25  acc: 60.39\n",
      "\n",
      "425/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.26  acc: 60.09\n",
      "\n",
      "426/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.25  acc: 60.30\n",
      "\n",
      "427/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.42  gen loss:  1.27  acc: 60.21\n",
      "\n",
      "428/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.24  acc: 60.29\n",
      "\n",
      "429/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.22  acc: 60.17\n",
      "\n",
      "430/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.27  acc: 60.16\n",
      "\n",
      "431/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.44  gen loss:  1.29  acc: 60.19\n",
      "\n",
      "432/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.28  acc: 60.18\n",
      "\n",
      "433/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.42  gen loss:  1.27  acc: 60.17\n",
      "\n",
      "434/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.24  acc: 60.23\n",
      "\n",
      "435/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.24  acc: 60.41\n",
      "\n",
      "436/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.25  acc: 60.12\n",
      "\n",
      "437/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.25  acc: 60.17\n",
      "\n",
      "438/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.44  gen loss:  1.35  acc: 60.30\n",
      "\n",
      "439/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.27  acc: 60.28\n",
      "\n",
      "440/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.26  acc: 60.28\n",
      "\n",
      "441/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.23  acc: 60.25\n",
      "\n",
      "442/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.44  gen loss:  1.28  acc: 60.36\n",
      "\n",
      "443/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.26  acc: 60.45\n",
      "\n",
      "444/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.45  gen loss:  1.27  acc: 60.25\n",
      "\n",
      "445/500 [====================] 782/782\n",
      "errD_real loss: -0.09  errD_fake loss:  0.41  gen loss:  1.27  acc: 60.28\n",
      "\n",
      "446/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.42  gen loss:  1.31  acc: 60.26\n",
      "\n",
      "447/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.42  gen loss:  1.23  acc: 60.44\n",
      "\n",
      "448/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.43  gen loss:  1.30  acc: 60.25\n",
      "\n",
      "449/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.24  acc: 60.29\n",
      "\n",
      "450/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.29  acc: 59.87\n",
      "\n",
      "451/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.43  gen loss:  1.32  acc: 60.33\n",
      "\n",
      "452/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.29  acc: 60.01\n",
      "\n",
      "453/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.44  gen loss:  1.29  acc: 60.53\n",
      "\n",
      "454/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.27  acc: 59.70\n",
      "\n",
      "455/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.23  acc: 60.38\n",
      "\n",
      "456/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.42  gen loss:  1.29  acc: 60.45\n",
      "\n",
      "457/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.44  gen loss:  1.26  acc: 60.62\n",
      "\n",
      "458/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.42  gen loss:  1.28  acc: 60.53\n",
      "\n",
      "459/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.24  acc: 60.39\n",
      "\n",
      "460/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.31  acc: 60.74\n",
      "\n",
      "461/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.45  gen loss:  1.26  acc: 60.25\n",
      "\n",
      "462/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.28  acc: 60.21\n",
      "\n",
      "463/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.20  acc: 60.40\n",
      "\n",
      "464/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.27  acc: 60.52\n",
      "\n",
      "465/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.25  acc: 60.65\n",
      "\n",
      "466/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.43  gen loss:  1.28  acc: 60.64\n",
      "\n",
      "467/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.42  gen loss:  1.28  acc: 60.13\n",
      "\n",
      "468/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.28  acc: 60.31\n",
      "\n",
      "469/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.27  acc: 60.42\n",
      "\n",
      "470/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.42  gen loss:  1.25  acc: 60.48\n",
      "\n",
      "471/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.44  gen loss:  1.27  acc: 60.76\n",
      "\n",
      "472/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.42  gen loss:  1.27  acc: 60.61\n",
      "\n",
      "473/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.28  acc: 60.57\n",
      "\n",
      "474/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.44  gen loss:  1.26  acc: 60.33\n",
      "\n",
      "475/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.26  acc: 60.42\n",
      "\n",
      "476/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.29  acc: 60.45\n",
      "\n",
      "477/500 [====================] 782/782\n",
      "errD_real loss: -0.09  errD_fake loss:  0.42  gen loss:  1.31  acc: 60.77\n",
      "\n",
      "478/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.43  gen loss:  1.29  acc: 60.29\n",
      "\n",
      "479/500 [====================] 782/782\n",
      "errD_real loss: -0.05  errD_fake loss:  0.44  gen loss:  1.26  acc: 60.26\n",
      "\n",
      "480/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.43  gen loss:  1.28  acc: 60.37\n",
      "\n",
      "481/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.26  acc: 60.62\n",
      "\n",
      "482/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.42  gen loss:  1.27  acc: 60.52\n",
      "\n",
      "483/500 [====================] 782/782\n",
      "errD_real loss: -0.09  errD_fake loss:  0.42  gen loss:  1.30  acc: 60.76\n",
      "\n",
      "484/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.43  gen loss:  1.32  acc: 60.45\n",
      "\n",
      "485/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.42  gen loss:  1.26  acc: 60.60\n",
      "\n",
      "486/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.43  gen loss:  1.25  acc: 60.60\n",
      "\n",
      "487/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.28  acc: 60.47\n",
      "\n",
      "488/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.44  gen loss:  1.21  acc: 60.21\n",
      "\n",
      "489/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.42  gen loss:  1.31  acc: 60.45\n",
      "\n",
      "490/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.44  gen loss:  1.26  acc: 60.45\n",
      "\n",
      "491/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.27  acc: 60.71\n",
      "\n",
      "492/500 [====================] 782/782\n",
      "errD_real loss: -0.06  errD_fake loss:  0.43  gen loss:  1.26  acc: 60.31\n",
      "\n",
      "493/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.44  gen loss:  1.32  acc: 60.52\n",
      "\n",
      "494/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.43  gen loss:  1.28  acc: 60.48\n",
      "\n",
      "495/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.43  gen loss:  1.29  acc: 61.03\n",
      "\n",
      "496/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.42  gen loss:  1.26  acc: 60.91\n",
      "\n",
      "497/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.42  gen loss:  1.32  acc: 60.57\n",
      "\n",
      "498/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.44  gen loss:  1.28  acc: 60.78\n",
      "\n",
      "499/500 [====================] 782/782\n",
      "errD_real loss: -0.07  errD_fake loss:  0.44  gen loss:  1.24  acc: 60.72\n",
      "\n",
      "500/500 [====================] 782/782\n",
      "errD_real loss: -0.08  errD_fake loss:  0.43  gen loss:  1.28  acc: 60.67\n",
      "\n",
      "500/500 [====================] 157/157\r"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "disc = ACGANDiscriminator().to(device)\n",
    "gen = ACGANGenerator(LATENT_DIM).to(device)\n",
    "\n",
    "disc.apply(weights_init)\n",
    "gen.apply(weights_init)\n",
    "\n",
    "disc_optim = optim.Adam(disc.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "gen_optim = optim.Adam(gen.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "disc_criterion = nn.BCELoss()\n",
    "aux_criterion = nn.NLLLoss()\n",
    "\n",
    "ACGAN_results  = train_acgan(disc, gen, disc_optim, gen_optim, disc_criterion, aux_criterion, 'models/ACGAN', train_dataloader, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
